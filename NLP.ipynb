{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAGuJKGExQg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NG7ea9gyCAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mM3zCekDL4Vc",
        "colab_type": "text"
      },
      "source": [
        "#web scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tmupg7MyMTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tables = pd.read_html(\"http://dollarrupee.in/gold-in-rupees-forecast-for-2015-2016-and-2017\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnnBuBcqMGME",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "outputId": "13e93ad1-08aa-4397-f85a-5810670924fd"
      },
      "source": [
        "df_daily = tables[0]\n",
        "df_daily.columns = df_daily.iloc[0]\n",
        "df_daily = df_daily[1:]\n",
        "tables[0]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Weekday</th>\n",
              "      <th>Min</th>\n",
              "      <th>Max</th>\n",
              "      <th>Price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Date</td>\n",
              "      <td>Weekday</td>\n",
              "      <td>Min</td>\n",
              "      <td>Max</td>\n",
              "      <td>Price</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>08.06</td>\n",
              "      <td>Monday</td>\n",
              "      <td>43633</td>\n",
              "      <td>44961</td>\n",
              "      <td>44297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>09.06</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>44152</td>\n",
              "      <td>45496</td>\n",
              "      <td>44824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.06</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>43597</td>\n",
              "      <td>44925</td>\n",
              "      <td>44261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.06</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>42924</td>\n",
              "      <td>44232</td>\n",
              "      <td>43578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>12.06</td>\n",
              "      <td>Friday</td>\n",
              "      <td>43053</td>\n",
              "      <td>44365</td>\n",
              "      <td>43709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>15.06</td>\n",
              "      <td>Monday</td>\n",
              "      <td>43297</td>\n",
              "      <td>44615</td>\n",
              "      <td>43956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>16.06</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>43760</td>\n",
              "      <td>45092</td>\n",
              "      <td>44426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>17.06</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>44033</td>\n",
              "      <td>45375</td>\n",
              "      <td>44704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>18.06</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>43250</td>\n",
              "      <td>44568</td>\n",
              "      <td>43909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>19.06</td>\n",
              "      <td>Friday</td>\n",
              "      <td>43068</td>\n",
              "      <td>44380</td>\n",
              "      <td>43724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>22.06</td>\n",
              "      <td>Monday</td>\n",
              "      <td>43465</td>\n",
              "      <td>44789</td>\n",
              "      <td>44127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23.06</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>42893</td>\n",
              "      <td>44199</td>\n",
              "      <td>43546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>24.06</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>42914</td>\n",
              "      <td>44222</td>\n",
              "      <td>43568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>25.06</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>43280</td>\n",
              "      <td>44598</td>\n",
              "      <td>43939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>26.06</td>\n",
              "      <td>Friday</td>\n",
              "      <td>42664</td>\n",
              "      <td>43964</td>\n",
              "      <td>43314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>29.06</td>\n",
              "      <td>Monday</td>\n",
              "      <td>43244</td>\n",
              "      <td>44562</td>\n",
              "      <td>43903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>30.06</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>43688</td>\n",
              "      <td>45018</td>\n",
              "      <td>44353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>01.07</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>44181</td>\n",
              "      <td>45527</td>\n",
              "      <td>44854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>02.07</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>43992</td>\n",
              "      <td>45332</td>\n",
              "      <td>44662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>03.07</td>\n",
              "      <td>Friday</td>\n",
              "      <td>44077</td>\n",
              "      <td>45419</td>\n",
              "      <td>44748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>06.07</td>\n",
              "      <td>Monday</td>\n",
              "      <td>43347</td>\n",
              "      <td>44667</td>\n",
              "      <td>44007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>07.07</td>\n",
              "      <td>Tuesday</td>\n",
              "      <td>44226</td>\n",
              "      <td>45572</td>\n",
              "      <td>44899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>08.07</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>43595</td>\n",
              "      <td>44923</td>\n",
              "      <td>44259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>09.07</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>43852</td>\n",
              "      <td>45188</td>\n",
              "      <td>44520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "0    Date    Weekday    Min    Max  Price\n",
              "0    Date    Weekday    Min    Max  Price\n",
              "1   08.06     Monday  43633  44961  44297\n",
              "2   09.06    Tuesday  44152  45496  44824\n",
              "3   10.06  Wednesday  43597  44925  44261\n",
              "4   11.06   Thursday  42924  44232  43578\n",
              "5   12.06     Friday  43053  44365  43709\n",
              "6   15.06     Monday  43297  44615  43956\n",
              "7   16.06    Tuesday  43760  45092  44426\n",
              "8   17.06  Wednesday  44033  45375  44704\n",
              "9   18.06   Thursday  43250  44568  43909\n",
              "10  19.06     Friday  43068  44380  43724\n",
              "11  22.06     Monday  43465  44789  44127\n",
              "12  23.06    Tuesday  42893  44199  43546\n",
              "13  24.06  Wednesday  42914  44222  43568\n",
              "14  25.06   Thursday  43280  44598  43939\n",
              "15  26.06     Friday  42664  43964  43314\n",
              "16  29.06     Monday  43244  44562  43903\n",
              "17  30.06    Tuesday  43688  45018  44353\n",
              "18  01.07  Wednesday  44181  45527  44854\n",
              "19  02.07   Thursday  43992  45332  44662\n",
              "20  03.07     Friday  44077  45419  44748\n",
              "21  06.07     Monday  43347  44667  44007\n",
              "22  07.07    Tuesday  44226  45572  44899\n",
              "23  08.07  Wednesday  43595  44923  44259\n",
              "24  09.07   Thursday  43852  45188  44520"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cu_m6FMZN6wm",
        "colab_type": "text"
      },
      "source": [
        "##Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4hyZTTaMMEK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename ='/FP.txt'\n",
        "file = open(filename, 'rt')\n",
        "text = file.read()\n",
        "file.close()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgnlH604P4Sp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "bfe49e78-c4d8-4465-a57e-e4ef0ad1ccdf"
      },
      "source": [
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences[0])\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens[:100])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "﻿This is financial Report of 2019-2020\n",
            "\n",
            "\n",
            "\n",
            "The share of large borrowers in Indian banks’ total loan portfolios stood at 53% as on March 2019\n",
            "\n",
            "The gross non-performing assets (NPAs) as a percentage of total loans stood at 9.3% as on March 2019\n",
            "\n",
            "Mumbai: Indian banks continue to see an improvement in asset quality with bad loans as a percentage of total loans expected to fall to 9% by March 2020, according to the Financial Stability Report released by the Reserve Bank of India (RBI) on Thursday.\n",
            "['\\ufeffThis', 'is', 'financial', 'Report', 'of', '2019-2020', 'The', 'share', 'of', 'large', 'borrowers', 'in', 'Indian', 'banks', '’', 'total', 'loan', 'portfolios', 'stood', 'at', '53', '%', 'as', 'on', 'March', '2019', 'The', 'gross', 'non-performing', 'assets', '(', 'NPAs', ')', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'stood', 'at', '9.3', '%', 'as', 'on', 'March', '2019', 'Mumbai', ':', 'Indian', 'banks', 'continue', 'to', 'see', 'an', 'improvement', 'in', 'asset', 'quality', 'with', 'bad', 'loans', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'expected', 'to', 'fall', 'to', '9', '%', 'by', 'March', '2020', ',', 'according', 'to', 'the', 'Financial', 'Stability', 'Report', 'released', 'by', 'the', 'Reserve', 'Bank', 'of', 'India', '(', 'RBI', ')', 'on', 'Thursday', '.', 'The', 'gross', 'non-performing']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e020lnatP_w4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "990c6cbe-5391-4839-a296-34be7b33f220"
      },
      "source": [
        "words = [word for word in tokens if word.isalpha()]\n",
        "print(words[:100])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['is', 'financial', 'Report', 'of', 'The', 'share', 'of', 'large', 'borrowers', 'in', 'Indian', 'banks', 'total', 'loan', 'portfolios', 'stood', 'at', 'as', 'on', 'March', 'The', 'gross', 'assets', 'NPAs', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'stood', 'at', 'as', 'on', 'March', 'Mumbai', 'Indian', 'banks', 'continue', 'to', 'see', 'an', 'improvement', 'in', 'asset', 'quality', 'with', 'bad', 'loans', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'expected', 'to', 'fall', 'to', 'by', 'March', 'according', 'to', 'the', 'Financial', 'Stability', 'Report', 'released', 'by', 'the', 'Reserve', 'Bank', 'of', 'India', 'RBI', 'on', 'Thursday', 'The', 'gross', 'assets', 'NPAs', 'as', 'a', 'percentage', 'of', 'total', 'loans', 'stood', 'at', 'as', 'on', 'March', 'According', 'to', 'the', 'report', 'stress', 'tests', 'done', 'on']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKlGh4tiZHzr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36eefb6f-15d3-4731-e294-bda326c39176"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmB_MTjcZMLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "adeee3d6-c66b-4d6a-b559-96c9dd4efd9a"
      },
      "source": [
        "from nltk.stem.porter import PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "stemmed = [porter.stem(word) for word in tokens]\n",
        "print(stemmed[:100])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\ufeffthi', 'is', 'financi', 'report', 'of', '2019-2020', 'the', 'share', 'of', 'larg', 'borrow', 'in', 'indian', 'bank', '’', 'total', 'loan', 'portfolio', 'stood', 'at', '53', '%', 'as', 'on', 'march', '2019', 'the', 'gross', 'non-perform', 'asset', '(', 'npa', ')', 'as', 'a', 'percentag', 'of', 'total', 'loan', 'stood', 'at', '9.3', '%', 'as', 'on', 'march', '2019', 'mumbai', ':', 'indian', 'bank', 'continu', 'to', 'see', 'an', 'improv', 'in', 'asset', 'qualiti', 'with', 'bad', 'loan', 'as', 'a', 'percentag', 'of', 'total', 'loan', 'expect', 'to', 'fall', 'to', '9', '%', 'by', 'march', '2020', ',', 'accord', 'to', 'the', 'financi', 'stabil', 'report', 'releas', 'by', 'the', 'reserv', 'bank', 'of', 'india', '(', 'rbi', ')', 'on', 'thursday', '.', 'the', 'gross', 'non-perform']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0frKI9czZxbN",
        "colab_type": "text"
      },
      "source": [
        "#CleanUp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eYO7e4mZefP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a081e099-a80a-490e-845f-e6741ab407d0"
      },
      "source": [
        "inp_tweets0 = pd.read_csv(\"/raw_tweets_economy.txt\", sep=\"\\t\")\n",
        "inp_tweets0.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Stocks losses deepen as a key recession warnin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>RT @CallMeAhmjusAyn: The #economy.\\r\\n@FoxNews...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AP Explains: Is the US economy nearing a reces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>A @JobCreatorsUSA / https://t.co/JXEt7hQU4k su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Who will stop mr. Mario Draghi and the ECB wit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                                  0\n",
              "0           0  Stocks losses deepen as a key recession warnin...\n",
              "1           1  RT @CallMeAhmjusAyn: The #economy.\\r\\n@FoxNews...\n",
              "2           2  AP Explains: Is the US economy nearing a reces...\n",
              "3           3  A @JobCreatorsUSA / https://t.co/JXEt7hQU4k su...\n",
              "4           4  Who will stop mr. Mario Draghi and the ECB wit..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDC1pxtGaSca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp_tweets0.drop('Unnamed: 0', inplace=True, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYcmUovGahMz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "99956d2a-309e-4b77-969c-2145f712dbf2"
      },
      "source": [
        "inp_tweets0 = inp_tweets0.rename({'0':'tweet'}, axis=1)\n",
        "inp_tweets0.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Stocks losses deepen as a key recession warnin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RT @CallMeAhmjusAyn: The #economy.\\r\\n@FoxNews...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AP Explains: Is the US economy nearing a reces...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A @JobCreatorsUSA / https://t.co/JXEt7hQU4k su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who will stop mr. Mario Draghi and the ECB wit...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet\n",
              "0  Stocks losses deepen as a key recession warnin...\n",
              "1  RT @CallMeAhmjusAyn: The #economy.\\r\\n@FoxNews...\n",
              "2  AP Explains: Is the US economy nearing a reces...\n",
              "3  A @JobCreatorsUSA / https://t.co/JXEt7hQU4k su...\n",
              "4  Who will stop mr. Mario Draghi and the ECB wit..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piynE-3EallF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tweet0=inp_tweets0['tweet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAhgqkjca1dv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "236103a3-9c14-4e48-f9b6-9c394e0ba69e"
      },
      "source": [
        "type(tweet0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3A5DyV_a3ZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txt=[x.lower() for x in tweet0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgtdfEH6bWFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "d8a39058-02db-4eb7-f438-78304e2a8de5"
      },
      "source": [
        "txt[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stocks losses deepen as a key recession warning surfaces @gop #economy #fail #collapse #recession #gop #greed… https://t.co/f8kazaixuk',\n",
              " \"rt @callmeahmjusayn: the #economy.\\r\\n@foxnews @realdonaldtrump \\r\\n#trump is an ejit.\\r\\n#maga #trumptrain2020 #sheeple are idiot's.\\r\\n#farming #trad…\",\n",
              " 'ap explains: is the us economy nearing a recession? \\r\\n#business\\r\\n#economy\\r\\n#recession\\r\\n#tradewar\\r\\n#china\\r\\n#eu… https://t.co/0jtsr2ksxi',\n",
              " 'a @jobcreatorsusa / https://t.co/jxet7hqu4k survey completed tuesday, 56% rated the #economy as good or excellent,… https://t.co/j1xmiptadx',\n",
              " 'who will stop mr. mario draghi and the ecb with this counterproductive course of money dumping / zero interests? it… https://t.co/eweirvuok0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWlUOf01dPgP",
        "colab_type": "text"
      },
      "source": [
        "#RE\n",
        "<table ><tr><th>Character</th><th>Description</th><th>Example Pattern Code</th><th >Exammple Match</th></tr>\n",
        "\n",
        "<tr ><td><span >\\d</span></td><td>A digit</td><td>file_\\d\\d</td><td>file_25</td></tr>\n",
        "\n",
        "<tr ><td><span >\\w</span></td><td>Alphanumeric</td><td>\\w-\\w\\w\\w</td><td>A-b_1</td></tr>\n",
        "\n",
        "\n",
        "\n",
        "<tr ><td><span >\\s</span></td><td>White space</td><td>a\\sb\\sc</td><td>a b c</td></tr>\n",
        "\n",
        "\n",
        "\n",
        "<tr ><td><span >\\D</span></td><td>A non digit</td><td>\\D\\D\\D</td><td>ABC</td></tr>\n",
        "\n",
        "<tr ><td><span >\\W</span></td><td>Non-alphanumeric</td><td>\\W\\W\\W\\W\\W</td><td>*-+=)</td></tr>\n",
        "\n",
        "<tr ><td><span >\\S</span></td><td>Non-whitespace</td><td>\\S\\S\\S\\S</td><td>Yoyo</td></tr></table>\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<table ><tr><th>Character</th><th>Description</th><th>Example Pattern Code</th><th >Exammple Match</th></tr>\n",
        "\n",
        "<tr ><td><span >+</span></td><td>Occurs one or more times</td><td>\tVersion \\w-\\w+</td><td>Version A-b1_1</td></tr>\n",
        "\n",
        "<tr ><td><span >{3}</span></td><td>Occurs exactly 3 times</td><td>\\D{3}</td><td>abc</td></tr>\n",
        "\n",
        "\n",
        "\n",
        "<tr ><td><span >{2,4}</span></td><td>Occurs 2 to 4 times</td><td>\\d{2,4}</td><td>123</td></tr>\n",
        "\n",
        "\n",
        "\n",
        "<tr ><td><span >{3,}</span></td><td>Occurs 3 or more</td><td>\\w{3,}</td><td>anycharacters</td></tr>\n",
        "\n",
        "<tr ><td><span >\\*</span></td><td>Occurs zero or more times</td><td>A\\*B\\*C*</td><td>AAACC</td></tr>\n",
        "\n",
        "<tr ><td><span >?</span></td><td>Once or none</td><td>plurals?</td><td>plural</td></tr></table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME6vbtUvbd7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "tweets_nouser = [re.sub(\"@\\w+\",\"\", twt) for twt in txt]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oGJrIWqeKKO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6bb2c50b-d21b-4574-f26b-bc85606c732b"
      },
      "source": [
        "tweets_nouser[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stocks losses deepen as a key recession warning surfaces  #economy #fail #collapse #recession #gop #greed… https://t.co/f8kazaixuk',\n",
              " \"rt : the #economy.\\r\\n  \\r\\n#trump is an ejit.\\r\\n#maga #trumptrain2020 #sheeple are idiot's.\\r\\n#farming #trad…\",\n",
              " 'ap explains: is the us economy nearing a recession? \\r\\n#business\\r\\n#economy\\r\\n#recession\\r\\n#tradewar\\r\\n#china\\r\\n#eu… https://t.co/0jtsr2ksxi',\n",
              " 'a  / https://t.co/jxet7hqu4k survey completed tuesday, 56% rated the #economy as good or excellent,… https://t.co/j1xmiptadx',\n",
              " 'who will stop mr. mario draghi and the ecb with this counterproductive course of money dumping / zero interests? it… https://t.co/eweirvuok0']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kB0bMTYxeM62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#URL removal\n",
        "tweets_nourl = [re.sub(\"\\w+://\\S+\",\"\", twt) for twt in tweets_nouser]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh81gihJeW4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hashtags0 = [re.findall('#\\w+',twt) for twt in tweets_nourl]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xkf6afWhgFXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tags=[]\n",
        "for twt in hashtags0:\n",
        "    tags.extend(twt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFGSnoRxgZn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_hashtags = [tag for tag in tags if tag not in '#economy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_CWEfUdgtCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "793ceca0-addd-4a87-ec2d-fcd2fd5c6439"
      },
      "source": [
        "len(all_hashtags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "813"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCWVz81wgyGd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "ee90ebc4-4d8f-4ea7-9d5d-0a5e87e741ed"
      },
      "source": [
        "from collections import Counter\n",
        "counts_hashtags = Counter(all_hashtags)\n",
        "counts_hashtags.most_common(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('#recession', 24),\n",
              " ('#india', 20),\n",
              " ('#business', 18),\n",
              " ('#hongkong', 17),\n",
              " ('#bloomberg', 15),\n",
              " ('#china', 12),\n",
              " ('#trump', 10),\n",
              " ('#markets', 9),\n",
              " ('#economics', 9),\n",
              " ('#infrastructure', 9)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vatp06RRhy_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res=counts_hashtags.most_common(10)\n",
        "res2 = {term:cnt for term, cnt in res}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkkUtQuIiQwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "012dddcd-53a5-41f1-e822-645c85a97060"
      },
      "source": [
        "plt.barh(list(res2.keys()), list(res2.values()), color=\"teal\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTj6MV6ElflZ",
        "colab_type": "text"
      },
      "source": [
        "#Word2vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koffLeRliUxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "w2v_model=Word2Vec(list_of_sentance,min_count=5,size=50, workers=4)\n",
        "print(w2v_model.wv.most_similar('great'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idIcTvNSmWLK",
        "colab_type": "text"
      },
      "source": [
        "#word Analogy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV5M8w4WmZTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# iterate through each sentence in the file \n",
        "data=[]\n",
        "for i in sent_tokenize(f): \n",
        "    temp = [] \n",
        "      \n",
        "    # tokenize the sentence into words \n",
        "    for j in word_tokenize(i): \n",
        "        temp.append(j.lower()) \n",
        "  \n",
        "    data.append(temp) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGLUcwfxm0vm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SKIP GRAM\n",
        "model2 = gensim.models.Word2Vec(data, min_count = 1, size = 100, \n",
        "                                             window = 5, sg = 1) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIxgalHfqKLD",
        "colab_type": "text"
      },
      "source": [
        "#Identify topics from news items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUafN6oOqFk3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oYadjOhqmiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "1ad3d76a-cc31-41b5-c5b2-a5761f903e42"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jI8AbDl5qnD-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1d80113-85c5-4913-f5d0-aca14853f350"
      },
      "source": [
        "print(WordNetLemmatizer().lemmatize('went', pos = 'v'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TAYQZHtqrMi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "outputId": "549fa52e-56c4-4de3-f0eb-8e5d0ee6ed0e"
      },
      "source": [
        "stemmer = SnowballStemmer(\"english\")\n",
        "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
        "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
        "           'traditional', 'reference', 'colonizer','plotted']\n",
        "singles = [stemmer.stem(plural) for plural in original_words]\n",
        "\n",
        "pd.DataFrame(data={'original word':original_words, 'stemmed':singles })"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original word</th>\n",
              "      <th>stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>caresses</td>\n",
              "      <td>caress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flies</td>\n",
              "      <td>fli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dies</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mules</td>\n",
              "      <td>mule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>denied</td>\n",
              "      <td>deni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>died</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>agreed</td>\n",
              "      <td>agre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>owned</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>humbled</td>\n",
              "      <td>humbl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sized</td>\n",
              "      <td>size</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>meeting</td>\n",
              "      <td>meet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>stating</td>\n",
              "      <td>state</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>siezing</td>\n",
              "      <td>siez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>itemization</td>\n",
              "      <td>item</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sensational</td>\n",
              "      <td>sensat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>traditional</td>\n",
              "      <td>tradit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>reference</td>\n",
              "      <td>refer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>colonizer</td>\n",
              "      <td>colon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>plotted</td>\n",
              "      <td>plot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   original word stemmed\n",
              "0       caresses  caress\n",
              "1          flies     fli\n",
              "2           dies     die\n",
              "3          mules    mule\n",
              "4         denied    deni\n",
              "5           died     die\n",
              "6         agreed    agre\n",
              "7          owned     own\n",
              "8        humbled   humbl\n",
              "9          sized    size\n",
              "10       meeting    meet\n",
              "11       stating   state\n",
              "12       siezing    siez\n",
              "13   itemization    item\n",
              "14   sensational  sensat\n",
              "15   traditional  tradit\n",
              "16     reference   refer\n",
              "17     colonizer   colon\n",
              "18       plotted    plot"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrKRA8a4q5ZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "d96b01d0-e948-4d14-eaef-958cf8d96ae5"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "# Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "    result=[]\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "            \n",
        "    return result\n",
        "\n",
        "document_num = 50\n",
        "doc_sample = 'This disk has failed many times. I would like to get it replaced.'\n",
        "\n",
        "print(\"Original document: \")\n",
        "words = []\n",
        "for word in doc_sample.split(' '):\n",
        "    words.append(word)\n",
        "print(words)\n",
        "print(\"\\n\\nTokenized and lemmatized document: \")\n",
        "print(preprocess(doc_sample))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original document: \n",
            "['This', 'disk', 'has', 'failed', 'many', 'times.', 'I', 'would', 'like', 'to', 'get', 'it', 'replaced.']\n",
            "\n",
            "\n",
            "Tokenized and lemmatized document: \n",
            "['disk', 'fail', 'time', 'like', 'replac']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs6tfHviwBJV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0a43f5d0-62e0-4e3a-8ac8-8d2cac7965ab"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', shuffle = True)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXJNuqlwwCEv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6c1781df-7ade-4e61-ae9f-206502d2a77f"
      },
      "source": [
        "processed_docs = []\n",
        "\n",
        "for doc in newsgroups_train.data:\n",
        "    processed_docs.append(preprocess(doc))\n",
        "\n",
        "print(processed_docs[:2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['lerxst', 'thing', 'subject', 'nntp', 'post', 'host', 'organ', 'univers', 'maryland', 'colleg', 'park', 'line', 'wonder', 'enlighten', 'door', 'sport', 'look', 'late', 'earli', 'call', 'bricklin', 'door', 'small', 'addit', 'bumper', 'separ', 'rest', 'bodi', 'know', 'tellm', 'model', 'engin', 'spec', 'year', 'product', 'histori', 'info', 'funki', 'look', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst'], ['guykuo', 'carson', 'washington', 'subject', 'clock', 'poll', 'final', 'summari', 'final', 'clock', 'report', 'keyword', 'acceler', 'clock', 'upgrad', 'articl', 'shelley', 'qvfo', 'innc', 'organ', 'univers', 'washington', 'line', 'nntp', 'post', 'host', 'carson', 'washington', 'fair', 'number', 'brave', 'soul', 'upgrad', 'clock', 'oscil', 'share', 'experi', 'poll', 'send', 'brief', 'messag', 'detail', 'experi', 'procedur', 'speed', 'attain', 'rat', 'speed', 'card', 'adapt', 'heat', 'sink', 'hour', 'usag', 'floppi', 'disk', 'function', 'floppi', 'especi', 'request', 'summar', 'day', 'network', 'knowledg', 'base', 'clock', 'upgrad', 'haven', 'answer', 'poll', 'thank', 'guykuo', 'washington']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv_ny9yLwK25",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "7171615f-6208-47b7-c619-6c3b3a48c000"
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "    print(k, v)\n",
        "    count += 1\n",
        "    if count > 10:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 addit\n",
            "1 bodi\n",
            "2 bricklin\n",
            "3 bring\n",
            "4 bumper\n",
            "5 call\n",
            "6 colleg\n",
            "7 door\n",
            "8 earli\n",
            "9 engin\n",
            "10 enlighten\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7Z63lFPwXAF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        },
        "outputId": "6e71b4e3-6768-4159-eb3c-c0b10a8db631"
      },
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n= 100000)\n",
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "\n",
        "document_num = 20\n",
        "bow_doc_x = bow_corpus[document_num]\n",
        "\n",
        "for i in range(len(bow_doc_x)):\n",
        "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
        "                                                     dictionary[bow_doc_x[i][0]], \n",
        "                                                     bow_doc_x[i][1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 18 (\"rest\") appears 1 time.\n",
            "Word 166 (\"clear\") appears 1 time.\n",
            "Word 336 (\"refer\") appears 1 time.\n",
            "Word 350 (\"true\") appears 1 time.\n",
            "Word 391 (\"technolog\") appears 1 time.\n",
            "Word 437 (\"christian\") appears 1 time.\n",
            "Word 453 (\"exampl\") appears 1 time.\n",
            "Word 476 (\"jew\") appears 1 time.\n",
            "Word 480 (\"lead\") appears 1 time.\n",
            "Word 482 (\"littl\") appears 3 time.\n",
            "Word 520 (\"wors\") appears 2 time.\n",
            "Word 721 (\"keith\") appears 3 time.\n",
            "Word 732 (\"punish\") appears 1 time.\n",
            "Word 803 (\"california\") appears 1 time.\n",
            "Word 859 (\"institut\") appears 1 time.\n",
            "Word 917 (\"similar\") appears 1 time.\n",
            "Word 990 (\"allan\") appears 1 time.\n",
            "Word 991 (\"anti\") appears 1 time.\n",
            "Word 992 (\"arriv\") appears 1 time.\n",
            "Word 993 (\"austria\") appears 1 time.\n",
            "Word 994 (\"caltech\") appears 2 time.\n",
            "Word 995 (\"distinguish\") appears 1 time.\n",
            "Word 996 (\"german\") appears 1 time.\n",
            "Word 997 (\"germani\") appears 3 time.\n",
            "Word 998 (\"hitler\") appears 1 time.\n",
            "Word 999 (\"livesey\") appears 2 time.\n",
            "Word 1000 (\"motto\") appears 2 time.\n",
            "Word 1001 (\"order\") appears 1 time.\n",
            "Word 1002 (\"pasadena\") appears 1 time.\n",
            "Word 1003 (\"pompous\") appears 1 time.\n",
            "Word 1004 (\"popul\") appears 1 time.\n",
            "Word 1005 (\"rank\") appears 1 time.\n",
            "Word 1006 (\"schneider\") appears 1 time.\n",
            "Word 1007 (\"semit\") appears 1 time.\n",
            "Word 1008 (\"social\") appears 1 time.\n",
            "Word 1009 (\"solntz\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCFRSmkIwePA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "a1bdb450-e02a-4a6d-e39a-a4a7ed7dff56"
      },
      "source": [
        "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
        "                                   num_topics = 8, \n",
        "                                   id2word = dictionary,                                    \n",
        "                                   passes = 10,\n",
        "                                   workers = 2)\n",
        "\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.014*\"window\" + 0.012*\"drive\" + 0.010*\"chip\" + 0.007*\"encrypt\" + 0.007*\"disk\" + 0.006*\"scsi\" + 0.006*\"control\" + 0.006*\"file\" + 0.006*\"clipper\" + 0.005*\"data\"\n",
            "\n",
            "\n",
            "Topic: 1 \n",
            "Words: 0.018*\"file\" + 0.011*\"program\" + 0.008*\"avail\" + 0.008*\"imag\" + 0.007*\"list\" + 0.006*\"version\" + 0.006*\"server\" + 0.006*\"window\" + 0.006*\"send\" + 0.006*\"sourc\"\n",
            "\n",
            "\n",
            "Topic: 2 \n",
            "Words: 0.010*\"space\" + 0.008*\"nasa\" + 0.007*\"govern\" + 0.004*\"orbit\" + 0.004*\"nation\" + 0.004*\"gun\" + 0.004*\"public\" + 0.004*\"weapon\" + 0.003*\"crime\" + 0.003*\"control\"\n",
            "\n",
            "\n",
            "Topic: 3 \n",
            "Words: 0.015*\"game\" + 0.013*\"team\" + 0.010*\"play\" + 0.009*\"player\" + 0.008*\"armenian\" + 0.006*\"hockey\" + 0.006*\"season\" + 0.005*\"leagu\" + 0.005*\"score\" + 0.004*\"basebal\"\n",
            "\n",
            "\n",
            "Topic: 4 \n",
            "Words: 0.006*\"bike\" + 0.004*\"engin\" + 0.003*\"drive\" + 0.003*\"food\" + 0.003*\"light\" + 0.003*\"caus\" + 0.003*\"power\" + 0.003*\"car\" + 0.003*\"littl\" + 0.002*\"medic\"\n",
            "\n",
            "\n",
            "Topic: 5 \n",
            "Words: 0.011*\"christian\" + 0.008*\"jesus\" + 0.006*\"exist\" + 0.005*\"moral\" + 0.005*\"bibl\" + 0.005*\"word\" + 0.004*\"life\" + 0.004*\"church\" + 0.004*\"claim\" + 0.004*\"religion\"\n",
            "\n",
            "\n",
            "Topic: 6 \n",
            "Words: 0.011*\"card\" + 0.010*\"sale\" + 0.007*\"price\" + 0.006*\"sell\" + 0.006*\"driver\" + 0.006*\"video\" + 0.005*\"offer\" + 0.005*\"cwru\" + 0.005*\"uiuc\" + 0.005*\"cleveland\"\n",
            "\n",
            "\n",
            "Topic: 7 \n",
            "Words: 0.009*\"israel\" + 0.007*\"isra\" + 0.007*\"govern\" + 0.006*\"jew\" + 0.006*\"presid\" + 0.005*\"kill\" + 0.005*\"turkish\" + 0.005*\"arab\" + 0.005*\"countri\" + 0.004*\"attack\"\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GuRRvKIwlWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://housing.com/in/buy/noida/house-noida?paid=true&gclid=Cj0KCQjwoPL2BRDxARIsAEMm9y_s4O9A9As25NRg4RIaUJGor3yyxE8OYEgi9KkubALd8oYOBmXtLy0aAnjGEALw_wcB\n",
        "#https://housing.com/in/buy/resale/page/4391406-3-bhk-independent-house-in-nagla-nagli-for-rs-4700000\n",
        "#https://www.magicbricks.com/propertyDetails/3-BHK-1475-Sq-ft-Villa-FOR-Sale-Sector-16-Block-B-in-Noida&id=4d423437393531373437\n",
        "#https://www.magicbricks.com/propertyDetails/3-BHK-1365-Sq-ft-Villa-FOR-Sale-Noida-Extension-in-Noida&id=4d423437373432343431"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQTohVwphd_u",
        "colab_type": "text"
      },
      "source": [
        "#search engine\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1YjK-Dtg_GO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inp_docs = pd.read_table(\"/r8-all-terms.txt\", sep=\"\\t\", names=['label','text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuCHC3sFhIBt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "5fe3fd0a-292f-4b33-c3d1-ce25371a61dc"
      },
      "source": [
        "inp_docs.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>earn</td>\n",
              "      <td>champion products ch approves stock split cham...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>acq</td>\n",
              "      <td>computer terminal systems cpml completes sale ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>earn</td>\n",
              "      <td>cobanco inc cbco year net shr cts vs dlrs net ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>earn</td>\n",
              "      <td>am international inc am nd qtr jan oper shr lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>earn</td>\n",
              "      <td>brown forman inc bfd th qtr net shr one dlr vs...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                               text\n",
              "0  earn  champion products ch approves stock split cham...\n",
              "1   acq  computer terminal systems cpml completes sale ...\n",
              "2  earn  cobanco inc cbco year net shr cts vs dlrs net ...\n",
              "3  earn  am international inc am nd qtr jan oper shr lo...\n",
              "4  earn  brown forman inc bfd th qtr net shr one dlr vs..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alywY8Y6iFE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article=inp_docs.text.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaHHGN8kiTWo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "fd21b5b0-a0da-4f89-a3ec-e0990f874bfd"
      },
      "source": [
        "article[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['champion products ch approves stock split champion products inc said its board of directors approved a two for one stock split of its common shares for shareholders of record as of april the company also said its board voted to recommend to shareholders at the annual meeting april an increase in the authorized capital stock from five mln to mln shares reuter ',\n",
              "       'computer terminal systems cpml completes sale computer terminal systems inc said it has completed the sale of shares of its common stock and warrants to acquire an additional one mln shares to sedio n v of lugano switzerland for dlrs the company said the warrants are exercisable for five years at a purchase price of dlrs per share computer terminal said sedio also has the right to buy additional shares and increase its total holdings up to pct of the computer terminal s outstanding common stock under certain circumstances involving change of control at the company the company said if the conditions occur the warrants would be exercisable at a price equal to pct of its common stock s market price at the time not to exceed dlrs per share computer terminal also said it sold the technolgy rights to its dot matrix impact technology including any future improvements to woodco inc of houston tex for dlrs but it said it would continue to be the exclusive worldwide licensee of the technology for woodco the company said the moves were part of its reorganization plan and would help pay current operation costs and ensure product delivery computer terminal makes computer generated labels forms tags and ticket printers and terminals reuter ',\n",
              "       'cobanco inc cbco year net shr cts vs dlrs net vs assets mln vs mln deposits mln vs mln loans mln vs mln note th qtr not available year includes extraordinary gain from tax carry forward of dlrs or five cts per shr reuter '],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUnpL6h2iV_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "article=[x.lower() for x in article]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdvKXiI5idSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c80e870e-7633-4120-e60c-4a8c85ac9369"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "words=[word_tokenize(x) for x in article]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7ZlCLqHlMdZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "20c3eec0-6871-4afd-887e-ea9c1ebc5dba"
      },
      "source": [
        "words[:1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['champion',\n",
              "  'products',\n",
              "  'ch',\n",
              "  'approves',\n",
              "  'stock',\n",
              "  'split',\n",
              "  'champion',\n",
              "  'products',\n",
              "  'inc',\n",
              "  'said',\n",
              "  'its',\n",
              "  'board',\n",
              "  'of',\n",
              "  'directors',\n",
              "  'approved',\n",
              "  'a',\n",
              "  'two',\n",
              "  'for',\n",
              "  'one',\n",
              "  'stock',\n",
              "  'split',\n",
              "  'of',\n",
              "  'its',\n",
              "  'common',\n",
              "  'shares',\n",
              "  'for',\n",
              "  'shareholders',\n",
              "  'of',\n",
              "  'record',\n",
              "  'as',\n",
              "  'of',\n",
              "  'april',\n",
              "  'the',\n",
              "  'company',\n",
              "  'also',\n",
              "  'said',\n",
              "  'its',\n",
              "  'board',\n",
              "  'voted',\n",
              "  'to',\n",
              "  'recommend',\n",
              "  'to',\n",
              "  'shareholders',\n",
              "  'at',\n",
              "  'the',\n",
              "  'annual',\n",
              "  'meeting',\n",
              "  'april',\n",
              "  'an',\n",
              "  'increase',\n",
              "  'in',\n",
              "  'the',\n",
              "  'authorized',\n",
              "  'capital',\n",
              "  'stock',\n",
              "  'from',\n",
              "  'five',\n",
              "  'mln',\n",
              "  'to',\n",
              "  'mln',\n",
              "  'shares',\n",
              "  'reuter']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNGJbowQlUH_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "768d3aab-a92f-4043-99a0-27e05e40e853"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "def del_stop(inp_tokens):\n",
        "    res = [term for term in inp_tokens if term not in stop_nltk]\n",
        "    return res\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_nltk = stopwords.words(\"english\")\n",
        "\n",
        "word = [del_stop(art) for art in words]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZez0914muCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer=TfidfVectorizer(max_features=3000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sX9rXjCnFNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "articles_string = [\" \".join(art) for art in word]\n",
        "articles_tfidf =vectorizer.fit_transform(articles_string)\n",
        "tfidf_dense = articles_tfidf.todense()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8et0oWDnl1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11d76b3f-5521-4cfb-9cc9-e6295cec780e"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(articles_tfidf[3,:],articles_tfidf[4,:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.51969816]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSyQ9eSxoYhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top5(target_row):\n",
        "    target_vector = tfidf_dense[target_row,:]\n",
        "    \n",
        "    sim_scores = []\n",
        "    for ind, vector in enumerate(tfidf_dense):\n",
        "        sim = cosine_similarity(target_vector, tfidf_dense[ind,:])[0][0]\n",
        "        sim_scores.append(sim)\n",
        "    \n",
        "    \n",
        "    similarity = pd.Series(sim_scores)\n",
        "    top5_scores = similarity.sort_values(ascending=False).head(6)[1:]\n",
        "    top5_index = top5_scores.index.values\n",
        "    \n",
        "    for ind in top5_index:\n",
        "        print(\"Similarity score:\" + str(round(top5_scores[ind],2)) + \"\\n\" + \"Article text: \" + articles_string[ind] + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHq6ZBAXqBbT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "31c4a168-ba0c-46ae-842a-d3717620cc59"
      },
      "source": [
        "get_top5(4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Similarity score:0.9\n",
            "Article text: technitrol inc tnl th qtr shr cts vs cts net mln vs revs mln vs mln year shr dlrs vs dlrs net mln vs mln revs mln vs mln reuter\n",
            "\n",
            "Similarity score:0.88\n",
            "Article text: vista resources inc vist th qtr net shr dlrs vs one dlr net vs revs mln vs mln mths shr dlrs vs dlrs net vs revs mln vs mln reuter\n",
            "\n",
            "Similarity score:0.87\n",
            "Article text: nike inc nike rd qtr feb net shr cts vs cts net vs mln revs mln vs mln nine mths shr cts vs dlrs net mln vs mln revs mln vs mln reuter\n",
            "\n",
            "Similarity score:0.87\n",
            "Article text: quick reilly group bqr th qtr feb shr cts vs cts net mln vs mln revs mln vs mln year shr dlrs vs dlr net mln vs mln revs mln vs mln reuter\n",
            "\n",
            "Similarity score:0.87\n",
            "Article text: kay jewelers inc kji th qtr net shr dlrs vs dlrs net mln vs revs mln vs mln year shr dlrs vs dlrs net vs revs mln vs mln reuter\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aYyiQAjqE8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_top5_query(qry):\n",
        "    #target_vector = tfidf_dense[target_row,:]\n",
        "    target_vector = vectorizer.transform([qry])\n",
        "    \n",
        "    sim_scores = []\n",
        "    for ind, vector in enumerate(tfidf_dense):\n",
        "        sim = cosine_similarity(target_vector, tfidf_dense[ind,:])[0][0]\n",
        "        sim_scores.append(sim)\n",
        "    \n",
        "    similarity = pd.Series(sim_scores)\n",
        "    top5_scores = similarity.sort_values(ascending=False).head(5)\n",
        "    top5_index = top5_scores.index.values\n",
        "    \n",
        "    print(\"Search query: \" + qry + \"\\n\")\n",
        "    \n",
        "    for ind in top5_index:\n",
        "        print(\"Similarity score:\" + str(round(top5_scores[ind],2)) + \"\\n\" + \"Article text: \" + articles_string[ind] + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze48NZk7qh16",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "fd6e8853-32b5-4e77-d287-45b1e9241d1d"
      },
      "source": [
        "get_top5_query(\"computer systems\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search query: computer systems\n",
            "\n",
            "Similarity score:0.55\n",
            "Article text: vertex vetx buy computer transceiver stake vertex industries inc computer transceiver systems inc jointly announced agreement vertex acquire pct interest computer completes proposed reorganization computer reorganization proceedings chapter since september companies said agreement would allow computer unsecured creditors debenture holders receive new stock exchange exsiting debt shareholders receive one new share computer stock four shares previously held companies said united states bankruptcy court southern district new york given preliminary approval proposal subject formal approval computer creditors court agreement vertex also said would supply computer dlrs operating funds arrange renegotiation secured bank debt among things reuter\n",
            "\n",
            "Similarity score:0.53\n",
            "Article text: aw computer systems inc awcsa year end dec shr cts vs cts net vs revs vs reuter\n",
            "\n",
            "Similarity score:0.48\n",
            "Article text: hogan systems hogn acquisition hogan systems inc said acquired systems inc durango colo mln dlrs hogan said systems provides integrated applications software processing services community banks systems revenues mln dlrs year hogan said reuter\n",
            "\n",
            "Similarity score:0.48\n",
            "Article text: altex aii sets acquisition computer firms altex industries inc said agreed principle buy pct two privately held affiliated computer retail companies undisclosed amount altex said denver based companies revenues seven mln dlrs last year integrated management data systems inc sells accounting software systems oil gas industry integrated management systems micro distribution division inc distributes micro computer products altex said expects close transaction subject financing july reuter\n",
            "\n",
            "Similarity score:0.46\n",
            "Article text: sci scis buys fortune fsys computer assets fortune systems corp sci systems inc said signed letter intent covering purchase fortune microcomputer business assets unspecified amount cash fortune systems makes desktop computer systems reuter\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYS92URFszUk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#compared String\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGvmVnX3qkwK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "a4640adf-11d0-453a-c280-a9bc9af5f639"
      },
      "source": [
        "!pip install fuzzywuzzy\n",
        "from fuzzywuzzy import process\n",
        "from fuzzywuzzy import fuzz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading https://files.pythonhosted.org/packages/43/ff/74f23998ad2f93b945c0309f825be92e04e0348e062026998b5eefef4c33/fuzzywuzzy-0.18.0-py2.py3-none-any.whl\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7DgpYgQtD6M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "06e16b03-ec56-4bba-c9fe-7b02ce190a21"
      },
      "source": [
        "diseases = ['Heart Attack', 'Brain Tumor', 'Lung Cancer', 'Fever', 'Throat Infection']\n",
        "instruments = [' electrocardiograph' , ' Sterilizers', ' Defibrillators', 'Thermometer', 'ICU']\n",
        "q= \" An electrocardiogram (ECG) is a medical test that detects cardiac (heart) abnormalities by measuring the electrical activity generated by the heart as it contracts. The machine that records the patient’s ECG is called an electrocardiograph.\"\n",
        "process.extract(q, diseases)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Heart Attack', 57),\n",
              " ('Fever', 34),\n",
              " ('Lung Cancer', 27),\n",
              " ('Brain Tumor', 26),\n",
              " ('Throat Infection', 25)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5tk6x7NtYSN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "c628c36c-406d-4af9-9435-beecc60bc439"
      },
      "source": [
        "process.extract(q, instruments)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(' electrocardiograph', 60),\n",
              " ('ICU', 38),\n",
              " ('Thermometer', 31),\n",
              " (' Defibrillators', 25),\n",
              " (' Sterilizers', 17)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxxeCmaXZEGP",
        "colab_type": "text"
      },
      "source": [
        "#aiml chatbot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewyYN8Z3uBhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "ef46ff74-4f93-45e1-ca54-ed7ef84cd795"
      },
      "source": [
        "!pip install aiml\n",
        "!pip install autocorrect\n",
        "import os\n",
        "import aiml\n",
        "from autocorrect import spell"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: aiml in /usr/local/lib/python3.6/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from aiml) (47.3.1)\n",
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFpzIMaKZFXD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "outputId": "73fb764b-f3a6-4209-a943-f6eb9b2b461c"
      },
      "source": [
        "\n",
        "BRAIN_FILE=\"/aiml_pretrained_model.dump\"\n",
        "\n",
        "k = aiml.Kernel()\n",
        "\n",
        "if os.path.exists(BRAIN_FILE):\n",
        "    print(\"Loading from brain file: \" + BRAIN_FILE)\n",
        "    k.loadBrain(BRAIN_FILE)\n",
        "else:\n",
        "    print(\"Parsing aiml files\")\n",
        "    k.bootstrap(learnFiles=\"D:/Bot/learningFileList.aiml\", commands=\"load aiml\")\n",
        "    print(\"Saving brain file: \" + BRAIN_FILE)\n",
        "    k.saveBrain(BRAIN_FILE)\n",
        "\n",
        "\n",
        "while True:\n",
        "    query = input(\"User > \")\n",
        "    query = [spell(w) for w in (query.split())]\n",
        "    question = \" \".join(query)\n",
        "    response = k.respond(question)\n",
        "    if response:\n",
        "        print(\"bot > \", response)\n",
        "    else:\n",
        "        print(\"bot > :) \", )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading from brain file: /aiml_pretrained_model.dump\n",
            "Loading brain from /aiml_pretrained_model.dump...done (101725 categories in 3.04 seconds)\n",
            "User > hey\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "bot >  Can I help you?\n",
            "User > how are you\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "bot >  I'm doing fine thanks how are you?\n",
            "User > bye\n",
            "autocorrect.spell is deprecated,             use autocorrect.Speller instead\n",
            "bot >  Sayonara.\n",
            "User > \n",
            "bot > :) \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-39fcc8934fc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"User > \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mspell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zonKXSYJEPj0",
        "colab_type": "text"
      },
      "source": [
        "# Spacy POS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNmspre8d56m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "from spacy.lang.en import English\n",
        "nlp = English()\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fw4FB7iFFAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=''' ram is playing cricket and he is trying very hard to score a century'''\n",
        "doc=nlp(text)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBh9_NFRHGYM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cec8d03d-bad9-4149-9cd1-83b64dc7bcc5"
      },
      "source": [
        "token_list = []\n",
        "for token in doc:\n",
        "    token_list.append(token.text)\n",
        "print(token_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', 'ram', 'is', 'playing', 'cricket', 'and', 'he', 'is', 'trying', 'very', 'hard', 'to', 'score', 'a', 'century']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vcbEa9ZHRKj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "2901822d-3392-47d8-81f5-3b60e7f6283b"
      },
      "source": [
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "docs=nlp(text)\n",
        "for word in docs:\n",
        "    print(word.text,word.pos_)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  SPACE\n",
            "ram PROPN\n",
            "is AUX\n",
            "playing VERB\n",
            "cricket NOUN\n",
            "and CCONJ\n",
            "he PRON\n",
            "is AUX\n",
            "trying VERB\n",
            "very ADV\n",
            "hard ADV\n",
            "to PART\n",
            "score VERB\n",
            "a DET\n",
            "century NOUN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw1ZkB3qJaJu",
        "colab_type": "text"
      },
      "source": [
        "#quick hack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExT6E0s5HZTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Remove all stop words\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    term for term in x.split() if term not in set(stop_words))\n",
        ")\n",
        "# Remove word stems using a Porter stemmer\n",
        "porter = nltk.PorterStemmer()\n",
        "processed = processed.apply(lambda x: ' '.join(\n",
        "    porter.stem(term) for term in x.split())\n",
        ")\n",
        "\n",
        "def preprocess_text(messy_string):\n",
        "    assert(type(messy_string) == str)\n",
        "    cleaned = re.sub(r'\\b[\\w\\-.]+?@\\w+?\\.\\w{2,4}\\b', 'emailaddr', messy_string)\n",
        "    cleaned = re.sub(r'(http[s]?\\S+)|(\\w+\\.[A-Za-z]{2,4}\\S*)', 'httpaddr',\n",
        "                     cleaned)\n",
        "    cleaned = re.sub(r'£|\\$', 'moneysymb', cleaned)\n",
        "    cleaned = re.sub(\n",
        "        r'\\b(\\+\\d{1,2}\\s)?\\d?[\\-(.]?\\d{3}\\)?[\\s.-]?\\d{3}[\\s.-]?\\d{4}\\b',\n",
        "        'phonenumbr', cleaned)\n",
        "    cleaned = re.sub(r'\\d+(\\.\\d+)?', 'numbr', cleaned)\n",
        "    cleaned = re.sub(r'[^\\w\\d\\s]', ' ', cleaned)\n",
        "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
        "    cleaned = re.sub(r'^\\s+|\\s+?$', '', cleaned.lower())\n",
        "    return ' '.join(\n",
        "        porter.stem(term) \n",
        "        for term in cleaned.split()\n",
        "        if term not in set(stop_words)\n",
        "    )\n",
        "\n",
        "\n",
        "#remove extra line breaks\n",
        "reviews_lower = [\" \".join(txt.split()) for txt in reviews_lower]\n",
        "\n",
        "reviews_tokens = [word_tokenize(sent) for sent in reviews_lower]\n",
        "#\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "stop_nltk = stopwords.words(\"english\")\n",
        "stop_punct = list(punctuation)\n",
        "#to remove specific word from stopword list\n",
        "stop_nltk.remove(\"not\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "stop_final = stop_nltk + stop_punct + [\"...\", \"``\",\"''\", \"====\", \"must\"]\n",
        "def del_stop(sent):\n",
        "    return [term for term in sent if term not in stop_final]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}